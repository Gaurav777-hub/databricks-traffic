{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce0cffd6-3423-4894-bf65-950684b157ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Workspace/Dev/04. Common\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a7f5bec-3bae-4cdc-ac77-b5894c3b6bf4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "%sql\n",
    "\n",
    "USE CATALOG `dev_catalog`;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "051860cf-055d-4cc1-8adc-e6ed3900d8b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "checkpoint = spark.sql(\"\"\"DESCRIBE EXTERNAL LOCATION checkpoints\"\"\").select(\"url\").collect()[0]['url']\n",
    "landing = spark.sql(\"\"\"DESCRIBE EXTERNAL LOCATION landing\"\"\").select(\"url\").collect()[0]['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d558e396-ed57-4cc1-9f68-c769960047ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dbutils.widgets.text(name=\"env\",defaultValue='',label='Enter the environment in lower case')\n",
    "env = dbutils.widgets.get(\"env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "871739bf-f22c-432c-bbc6-b137330a9279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_Traffic_Data():\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    print(\"Reading the Raw Traffic Data :  \", end='')\n",
    "    schema = StructType([\n",
    "    StructField(\"Record_ID\",IntegerType()),\n",
    "    StructField(\"Count_point_id\",IntegerType()),\n",
    "    StructField(\"Direction_of_travel\",StringType()),\n",
    "    StructField(\"Year\",IntegerType()),\n",
    "    StructField(\"Count_date\",StringType()),\n",
    "    StructField(\"hour\",IntegerType()),\n",
    "    StructField(\"Region_id\",IntegerType()),\n",
    "    StructField(\"Region_name\",StringType()),\n",
    "    StructField(\"Local_authority_name\",StringType()),\n",
    "    StructField(\"Road_name\",StringType()),\n",
    "    StructField(\"Road_Category_ID\",IntegerType()),\n",
    "    StructField(\"Start_junction_road_name\",StringType()),\n",
    "    StructField(\"End_junction_road_name\",StringType()),\n",
    "    StructField(\"Latitude\",DoubleType()),\n",
    "    StructField(\"Longitude\",DoubleType()),\n",
    "    StructField(\"Link_length_km\",DoubleType()),\n",
    "    StructField(\"Pedal_cycles\",IntegerType()),\n",
    "    StructField(\"Two_wheeled_motor_vehicles\",IntegerType()),\n",
    "    StructField(\"Cars_and_taxis\",IntegerType()),\n",
    "    StructField(\"Buses_and_coaches\",IntegerType()),\n",
    "    StructField(\"LGV_Type\",IntegerType()),\n",
    "    StructField(\"HGV_Type\",IntegerType()),\n",
    "    StructField(\"EV_Car\",IntegerType()),\n",
    "    StructField(\"EV_Bike\",IntegerType())\n",
    "    ])\n",
    "    rawTraffic_stream = (spark.readStream\n",
    "                     .format(\"cloudFiles\")\n",
    "                     .option(\"cloudFiles.format\", \"csv\")\n",
    "                     .option(\"cloudFiles.schemaLocation\",f\"{checkpoint}rawTraffilcLoad/schemaInfer\")\n",
    "                     .option(\"header\",\"true\")\n",
    "                     .schema(schema)\n",
    "                     .load(landing+'raw_traffic/')\n",
    "                     .withColumn(\"Extract_Time\",current_timestamp())\n",
    "                     )\n",
    "    print('Reading Succcess !!')\n",
    "    print('*******************')\n",
    "\n",
    "    return rawTraffic_stream "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bdc29a6-5c26-428c-88e8-407baba9c563",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_Traffic_Data(read_Df,env):\n",
    "    writeStream = (read_Df.writeStream\n",
    "               .format(\"delta\")\n",
    "               .option(\"checkpointLocation\",checkpoint+\"rawTraffic/Checkpt\")\n",
    "               .outputMode(\"append\")\n",
    "               .trigger(availableNow=True)\n",
    "               .queryName('rawTrafficWriteStream')\n",
    "               .toTable(f\"`{env}_catalog`.`bronze`.`raw_traffic`\")\n",
    "                )\n",
    "    # writeStream.awaitTermination()\n",
    "    print('Write Success')\n",
    "    print(\"****************************\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba95f2ab-266f-41c8-8ed3-ae5e03353b17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    " spark.sql(\"\"\"Select count(1) from `dev_catalog`.`bronze`.`raw_traffic`\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9ff349d-cff2-431c-b0b1-e1abac80a5a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_Road_Data():\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "    from pyspark.sql.functions import current_timestamp\n",
    "    print(\"Reading the Raw Roads Data :  \", end='')\n",
    "    schema = StructType([\n",
    "        StructField('Road_ID',IntegerType()),\n",
    "        StructField('Road_Category_Id',IntegerType()),\n",
    "        StructField('Road_Category',StringType()),\n",
    "        StructField('Region_ID',IntegerType()),\n",
    "        StructField('Region_Name',StringType()),\n",
    "        StructField('Total_Link_Length_Km',DoubleType()),\n",
    "        StructField('Total_Link_Length_Miles',DoubleType()),\n",
    "        StructField('All_Motor_Vehicles',DoubleType())\n",
    "        ])\n",
    "    \n",
    "    rawRoads_stream = (spark.readStream\n",
    "                     .format(\"cloudFiles\")\n",
    "                     .option(\"cloudFiles.format\", \"csv\")\n",
    "                     .option(\"cloudFiles.schemaLocation\",f\"{checkpoint}rawRoads/schemaInfer\")\n",
    "                     .option(\"header\",\"true\")\n",
    "                     .schema(schema)\n",
    "                     .load(landing+'raw_roads/')\n",
    "                     )\n",
    "    print('Reading Succcess !!')\n",
    "    print('*******************')\n",
    "\n",
    "    return rawRoads_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e57bd4e-26c9-46f3-af75-2493df757d6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# display(streamingdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10b0dd10-02c4-415b-82f5-510065ff6ba9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_roads_data(streamingdf,env):\n",
    "    writeStream = (streamingdf.writeStream\n",
    "               .format(\"delta\")\n",
    "               .option(\"checkpointLocation\",checkpoint+\"rawRoads/Checkpt\")\n",
    "               .outputMode(\"append\")\n",
    "               .trigger(availableNow=True)\n",
    "               .queryName('rawRoadsWriteStream')\n",
    "               .toTable(f\"`{env}_catalog`.`bronze`.`raw_roads`\")\n",
    "    )\n",
    "                \n",
    "    # writeStream.awaitTermination()\n",
    "    print('Write Success')\n",
    "    print(\"****************************\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bab798f5-9112-475a-8486-61ff983c4ea6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Read traffic data \n",
    "read_Df = read_Traffic_Data()\n",
    "\n",
    "#Load traffic data\n",
    "write_Traffic_Data(read_Df,env)\n",
    "\n",
    "#Read traffic data \n",
    "streamingdf = read_Road_Data() \n",
    "\n",
    "#Load roads data\n",
    "write_roads_data(streamingdf,env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5577757-f9d7-4ea5-9f07-d1c0a3f66e61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    " %skip\n",
    "# spark.sql(\"\"\"Select * from `dev_catalog`.`bronze`.`raw_roads`\"\"\").display()\n",
    "spark.sql(\"\"\"Select count(1) from `dev_catalog`.`bronze`.`raw_traffic`\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "790b4836-883e-43c4-a8b2-974f51dda382",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "streamingf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5792b1e-adfe-47d5-b06b-63515adb6ef1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "spark.sql(\"\"\"Select * from `dev_catalog`.`bronze`.`raw_roads`\"\"\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "654b209d-e6bc-4de8-b661-58d6566a862a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5340829559071695,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02. Load Bronze Data",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "3696305e-e2d3-4506-a51f-492f583af27a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
